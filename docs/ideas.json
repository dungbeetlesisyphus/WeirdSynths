{
  "meta": {
    "plugin": "WeirdSynths",
    "description": "AI-generated VCV Rack Pro 2 module ideas — rate them to build the roadmap",
    "lastGenerated": "2026-02-23",
    "totalIdeas": 20
  },
  "ideas": [
    {
      "id": "001",
      "name": "BLINK",
      "tagline": "your eyelids become the beat",
      "category": "Sequencer",
      "hp": 8,
      "concept": "Detects eye blinks via webcam using landmark occlusion ratios. Each blink fires a trigger. Blink rate (blinks per minute) outputs a 0–10V CV for BPM sync or modulation. Closed-eye duration controls gate length — a slow blink = long gate, fast blink = snappy trigger.",
      "keyFeature": "Involuntary blinking creates inherently human, non-quantized rhythm",
      "inputs": ["RESET", "THRESH CV"],
      "outputs": ["TRIG", "GATE", "RATE", "DURATION"],
      "params": ["THRESHOLD", "SENSITIVITY", "SMOOTH"],
      "inspiration": "Morse code and involuntary human nervous system rhythm",
      "bodyPart": "eyes",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "002",
      "name": "BREATH",
      "tagline": "inhale attack, exhale release",
      "category": "Envelope",
      "hp": 10,
      "concept": "Tracks breathing rhythm via chest movement or nostril landmark oscillation. Outputs a slow, organic envelope that follows the breath cycle — inhale rises, exhale falls. Breath depth controls amplitude. Respiratory rate drives a BPM-synced clock output. Works as a living LFO that never quite repeats.",
      "keyFeature": "The envelope is literally alive — it fluctuates with body state, stress, and focus",
      "inputs": ["GATE", "DEPTH CV"],
      "outputs": ["ENV", "INHALE TRIG", "EXHALE TRIG", "RATE"],
      "params": ["DEPTH", "SMOOTH", "RATE SCALE"],
      "inspiration": "Pranayama breath control techniques and biofeedback music therapy",
      "bodyPart": "nose / chest",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "003",
      "name": "IRIS",
      "tagline": "where you look shapes the sound",
      "category": "CV Source",
      "hp": 12,
      "concept": "Tracks gaze direction and pupil size via eye landmark geometry. Horizontal gaze outputs stereo pan CV. Vertical gaze controls filter cutoff. Pupil dilation (estimated from iris-to-sclera ratio) outputs an arousal/attention CV — dilated = excited, contracted = calm. Look left to pan, look up to open the filter.",
      "keyFeature": "Pupil dilation as an unconscious arousal meter — music responds to what you feel, not what you perform",
      "inputs": ["PAN CV", "FILTER CV"],
      "outputs": ["GAZE X", "GAZE Y", "PUPIL", "ATTENTION"],
      "params": ["GAZE SCALE", "PUPIL SCALE", "SMOOTH", "DEADZONE"],
      "inspiration": "Eye tracking interfaces and the psychology of pupillary response",
      "bodyPart": "eyes",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "004",
      "name": "HAND",
      "tagline": "21 joints, infinite expression",
      "category": "CV Source",
      "hp": 16,
      "concept": "Tracks hand pose via MediaPipe Hands — 21 landmarks per hand. Finger spread controls chord width CV. Each finger's curl outputs individual gates (make a fist = all gates high). Wrist rotation outputs 0–10V. Pinch gesture fires a trigger. Two-hand mode allows left/right independent CV lanes.",
      "keyFeature": "Finger curl gates mean you can mute/unmute individual voices just by curling fingers",
      "inputs": ["HAND SELECT", "CALIBRATE"],
      "outputs": ["SPREAD", "WRIST", "PINCH TRIG", "THUMB GATE", "INDEX GATE", "MIDDLE GATE", "RING GATE", "PINKY GATE"],
      "params": ["HAND", "SMOOTH", "SCALE"],
      "inspiration": "Theremin hand positioning and classical conducting gesture vocabulary",
      "bodyPart": "hands",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "005",
      "name": "ECHO",
      "tagline": "loop your face, haunt yourself",
      "category": "Sequencer",
      "hp": 14,
      "concept": "Records a buffer of face landmark CV data (up to 32 seconds) and plays it back as a sequence. While playing, live face data can be blended in via a MIX knob — creating a ghost of your past expression layered with your present one. Ideal for polyrhythmic CV generation where one 'performer' is yourself from 4 bars ago.",
      "keyFeature": "Blend live and recorded face at any ratio — perform a duet with yourself",
      "inputs": ["RECORD", "PLAY", "STOP", "BLEND CV"],
      "outputs": ["PLAY CV x8", "RECORDING LED", "POSITION"],
      "params": ["LENGTH", "BLEND", "SPEED", "LOOP MODE"],
      "inspiration": "Frippertronics tape loop technique and echo delay performance",
      "bodyPart": "face (recorded)",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "006",
      "name": "TWIN",
      "tagline": "morph between two performers",
      "category": "CV Source",
      "hp": 12,
      "concept": "Accepts two face data streams (from two cameras or two people appearing in one camera frame) and outputs morphed CV between them. MORPH knob (and CV input) interpolates smoothly from Face A to Face B. Use it to blend two performers' expressions, or to create 'averaged emotion' states that neither performer holds alone.",
      "keyFeature": "Musical averaging of two human emotional states — a third synthetic performer who is neither of you",
      "inputs": ["FACE A IN", "FACE B IN", "MORPH CV"],
      "outputs": ["MORPH x12", "FACE A CONFIDENCE", "FACE B CONFIDENCE"],
      "params": ["MORPH", "SMOOTH", "INTERPOLATION"],
      "inspiration": "Cross-synthesis in audio and the morphing face computer graphics research of the 90s",
      "bodyPart": "two faces",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "007",
      "name": "DRIFT",
      "tagline": "micro-tremors become macro music",
      "category": "Modulator",
      "hp": 8,
      "concept": "Extracts involuntary micro-jitter from face landmark positions — the tiny, sub-perceptual tremors that even a still face exhibits. Amplifies and slow-tracks this noise floor into usable modulation CV. Maps to a very slow, organic, never-repeating LFO-like signal that sounds nothing like a sine wave or triangle.",
      "keyFeature": "Biological noise floor as a modulation source — uniquely human, never quantizable, endlessly variable",
      "inputs": ["LANDMARK IN", "SCALE CV"],
      "outputs": ["DRIFT OUT", "JITTER", "MAGNITUDE"],
      "params": ["AMPLIFY", "SMOOTH", "RATE SCALE", "CHARACTER"],
      "inspiration": "Stochastic resonance and the musical use of biological tremor in instruments like the erhu and voice",
      "bodyPart": "face (involuntary movement)",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "008",
      "name": "TEMPO",
      "tagline": "nod your head, set the clock",
      "category": "Utility",
      "hp": 6,
      "concept": "Detects rhythmic head movement — nodding, swaying, head-bobbing to a beat — and converts it to a stable musical clock. Tracks the period of the nodding motion and outputs a quantized BPM clock with swing detection. When you feel the groove and move, the rack feels it too.",
      "keyFeature": "Tap tempo via head-nodding — the most natural BPM input imaginable",
      "inputs": ["RESET", "MULT CV"],
      "outputs": ["CLOCK", "SWING", "BPM CV", "TAP TRIG"],
      "params": ["MULTIPLIER", "DIVISION", "SMOOTH", "SENSITIVITY"],
      "inspiration": "Conductors setting tempo with body movement and African call-and-response rhythm traditions",
      "bodyPart": "head movement",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "009",
      "name": "CROWD",
      "tagline": "many faces, one signal",
      "category": "CV Source",
      "hp": 12,
      "concept": "Detects and tracks up to 8 faces in a camera frame simultaneously. Outputs aggregate emotion statistics — average valence (happy/sad), average arousal, face count CV. Individual face positions output as X/Y pairs for spatial audio control. Designed for installation art, live performance with audience tracking, or two-person live sets.",
      "keyFeature": "Audience becomes part of the instrument — crowd mood modulates the performance in real time",
      "inputs": ["CALIBRATE", "WEIGHT CV"],
      "outputs": ["COUNT", "AVG VALENCE", "AVG AROUSAL", "FACE 1-8 X", "FACE 1-8 Y"],
      "params": ["MAX FACES", "SMOOTH", "WEIGHT MODE"],
      "inspiration": "Group flow states, mob psychology research, and Brian Eno's ambient music theory",
      "bodyPart": "multiple faces",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "010",
      "name": "LIP",
      "tagline": "read my lips — into the filter",
      "category": "Filter",
      "hp": 10,
      "concept": "Dedicated vowel-shape and lip-movement analyzer. Detects A/E/I/O/U vowel shapes from lip landmark geometry and outputs discrete CV per vowel (0V=silent, 5V=full vowel). Lip openness controls filter cutoff, lip rounding controls resonance Q, lip corner stretch controls stereo width. Silent input triggers decay envelope.",
      "keyFeature": "Mouth shapes directly mapped to formant filter — the module lip-synchs to you",
      "inputs": ["AUDIO IN", "CUTOFF CV"],
      "outputs": ["VOWEL A", "VOWEL E", "VOWEL I", "VOWEL O", "VOWEL U", "OPENNESS", "ROUNDNESS"],
      "params": ["SENSITIVITY", "SMOOTH", "VOWEL SCALE"],
      "inspiration": "Vocoder phoneme analysis and the articulatory phonetics of vocal tract shaping",
      "bodyPart": "mouth / lips",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "011",
      "name": "SCAR",
      "tagline": "asymmetry is the texture",
      "category": "Modulator",
      "hp": 8,
      "concept": "Measures facial asymmetry in real time — the difference between left and right sides of the face. Natural asymmetry (everyone has it) outputs a slow-moving CV representing your baseline character. Dynamic asymmetry from expressions (smirking, winking, uneven brow) outputs as a fast modulation signal. Use asymmetry as a stereo spread or waveshaper amount.",
      "keyFeature": "Your face's natural imperfection becomes a unique, non-cloneable CV fingerprint",
      "inputs": ["SCALE CV"],
      "outputs": ["ASYMMETRY", "LEFT WEIGHT", "RIGHT WEIGHT", "DELTA"],
      "params": ["SMOOTH", "SCALE", "BASELINE MODE"],
      "inspiration": "The study of facial dimorphism and the musical concept of imperfection as character (wabi-sabi)",
      "bodyPart": "face (left/right comparison)",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "012",
      "name": "TIDE",
      "tagline": "slow trends, deep modulation",
      "category": "Modulator",
      "hp": 6,
      "concept": "Long-form trend analyzer for face CV data. Accepts any CV input and computes a slow-moving weighted average over 1–60 second windows. Detects whether you're trending more expressive or more neutral over time. Ideal for very slow compositional shifts — opening up a filter over a minute of gradually increasing emotional intensity.",
      "keyFeature": "Captures the arc of a performance, not just the moment — emotional storytelling at the CV level",
      "inputs": ["CV IN", "WINDOW CV"],
      "outputs": ["TREND", "DERIVATIVE", "PEAK", "VALLEY"],
      "params": ["WINDOW", "SMOOTH", "TRACKING SPEED"],
      "inspiration": "Tidal forces, ocean dynamics, and the musical concept of large-scale formal shape",
      "bodyPart": "any (CV aggregator)",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "013",
      "name": "SPINE",
      "tagline": "posture determines pitch",
      "category": "CV Source",
      "hp": 12,
      "concept": "Tracks upper body posture using MediaPipe Pose landmarks. Shoulder angle outputs stereo tilt CV. Spine curvature (slouch vs straight) outputs a long-form modulation signal — bad posture makes music that sounds… wrong, motivating correction. Head tilt relative to shoulders outputs pitch bend CV. Designed to reward expressive physical performance.",
      "keyFeature": "Music that responds to how you carry yourself — physical tension and release becomes sonic tension and release",
      "inputs": ["CALIBRATE", "TILT CV"],
      "outputs": ["SHOULDER ANGLE", "SPINE CURVE", "HEAD TILT", "LEAN X", "LEAN Y"],
      "params": ["SENSITIVITY", "SMOOTH", "CALIBRATION"],
      "inspiration": "Feldenkrais method, Alexander Technique, and Laurie Anderson's body-as-instrument performances",
      "bodyPart": "spine / shoulders",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "014",
      "name": "SNARL",
      "tagline": "teeth, tension, distortion",
      "category": "Effect",
      "hp": 10,
      "concept": "Audio waveshaper whose character is controlled by facial tension signals — brow furrow, jaw clench, lip compression. Neutral face = clean signal through. Intense scowl = heavy saturation and bit crush. Teeth bared = harsh clipping with high-order harmonics. The angrier you look, the more destroyed the audio.",
      "keyFeature": "Distortion that responds to your emotional state — performing aggression makes the sound aggressive",
      "inputs": ["AUDIO IN", "TENSION CV", "MIX CV"],
      "outputs": ["AUDIO OUT", "TENSION LEVEL"],
      "params": ["DRIVE", "SHAPE", "MIX", "CHARACTER"],
      "inspiration": "The link between facial muscle tension and vocal distortion in aggressive singing styles",
      "bodyPart": "jaw / brow",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "015",
      "name": "BLUSH",
      "tagline": "shame and warmth as filter color",
      "category": "Filter",
      "hp": 8,
      "concept": "Analyzes facial skin color temperature in cheek regions via color histogram sampling. Increased redness (from exertion, excitement, embarrassment) shifts a warm/cold filter character. Cool skin = bright, clinical high-pass character. Warm/flushed skin = dark, saturated low-pass. Uses HSV color space to track hue shift independent of lighting changes.",
      "keyFeature": "Involuntary physiological responses (blushing, pallor) become filter parameters — the body cannot lie",
      "inputs": ["AUDIO IN", "WARMTH CV"],
      "outputs": ["AUDIO OUT", "WARMTH", "RED LEVEL"],
      "params": ["SENSITIVITY", "SMOOTH", "RESPONSE CURVE"],
      "inspiration": "Thermal imaging music visualization and the concept of body temperature as an emotional indicator",
      "bodyPart": "skin (cheeks)",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "016",
      "name": "MORPH",
      "tagline": "continuous between six emotion states",
      "category": "CV Source",
      "hp": 14,
      "concept": "Tracks the six basic Ekman emotions (happy, sad, angry, surprised, disgusted, fearful) and outputs continuous 0–10V per emotion. Also outputs a 2D XY coordinate in Valence-Arousal space — the Russell circumplex model of emotion. Great for controlling 6 voices in a generative patch where each emotion state modulates a different aspect of the sound.",
      "keyFeature": "All six emotions live simultaneously as independent CVs — complex emotional blends create complex harmonic blends",
      "inputs": ["CALIBRATE", "SCALE CV"],
      "outputs": ["HAPPY", "SAD", "ANGRY", "SURPRISE", "DISGUST", "FEAR", "VALENCE", "AROUSAL"],
      "params": ["SENSITIVITY", "SMOOTH", "BASELINE"],
      "inspiration": "Paul Ekman's universal emotion research and Russell's circumplex model of affect",
      "bodyPart": "whole face (expression)",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "017",
      "name": "JAW",
      "tagline": "chew the beat",
      "category": "Sequencer",
      "hp": 8,
      "concept": "Focused jaw movement tracker — faster and more accurate than NERVE's general jaw output. Tracks jaw open/close velocity, rhythmic chewing motion, and lateral jaw slide. Rhythmic jaw movement (like silently chewing to a beat) outputs a trigger sequence. Jaw position outputs a continuous CV for VCA or filter control. Clenching outputs a gate.",
      "keyFeature": "Muscle memory from chewing creates surprisingly consistent rhythmic triggers — a percussion instrument built into everyone",
      "inputs": ["THRESHOLD CV", "RESET"],
      "outputs": ["JAW CV", "OPEN TRIG", "CLOSE TRIG", "RHYTHM GATE", "CLENCH"],
      "params": ["THRESHOLD", "SMOOTH", "VELOCITY SENSITIVITY"],
      "inspiration": "The jaw harp (jew's harp) and the rhythmic clicking of jaw movements in some throat singing traditions",
      "bodyPart": "jaw",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "018",
      "name": "STILL",
      "tagline": "silence is a CV",
      "category": "Utility",
      "hp": 6,
      "concept": "Inverted activity detector — outputs maximum CV when the performer is completely still, and drops to zero when movement is detected. Use it to fade out effects when you're moving (performing) and bring them back when you go still (contemplating). Also outputs a 'stillness streak' counter — how many seconds you've been motionless.",
      "keyFeature": "Rewards stillness — creates musical moments of held breath when the performer stops moving",
      "inputs": ["THRESHOLD CV", "GATE"],
      "outputs": ["STILL CV", "MOTION TRIG", "STILL TRIG", "STREAK"],
      "params": ["THRESHOLD", "SMOOTH", "DECAY"],
      "inspiration": "John Cage's 4'33\", Buddhist meditation timers, and the musical use of silence as compositional material",
      "bodyPart": "whole body (absence of movement)",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "019",
      "name": "WINK",
      "tagline": "each eye has its own track",
      "category": "Utility",
      "hp": 6,
      "concept": "Dedicated left/right eye wink detector with configurable hold time. Left wink fires one trigger lane, right wink fires another — independently. Hold one eye closed for sustained gate. Both eyes closed = third output gate. Use it for live performance switching, A/B track selection, mute/unmute, or as a two-button CV keyboard played with your face.",
      "keyFeature": "A two-button controller you never have to reach for — it's already on your face",
      "inputs": ["HOLD CV"],
      "outputs": ["LEFT TRIG", "RIGHT TRIG", "BOTH GATE", "LEFT GATE", "RIGHT GATE"],
      "params": ["HOLD TIME", "DEBOUNCE", "SENSITIVITY"],
      "inspiration": "Morse code keyers, eye tracking accessibility controllers, and binary wink-based communication systems",
      "bodyPart": "eyes (left/right independently)",
      "generated": "2026-02-23",
      "rating": null
    },
    {
      "id": "020",
      "name": "SKIN",
      "tagline": "texture of your face as oscillator",
      "category": "Oscillator",
      "hp": 12,
      "concept": "Analyzes facial skin texture variance (micro-wrinkles, pores, surface detail) via camera zoom region and maps it to oscillator timbre. Smoother skin = cleaner waveform, more sine-like. Coarser/more textured skin regions = richer harmonic content, more sawtooth-like. As lighting or expression changes skin apparent texture, the timbre shifts. Works as a live wavetable driven by your face's surface.",
      "keyFeature": "Your skin IS the wavetable — lighting angle changes timbre as shadows deepen texture",
      "inputs": ["V/OCT", "FM CV", "TEXTURE SCALE"],
      "outputs": ["AUDIO OUT", "TEXTURE CV", "HARMONIC INDEX"],
      "params": ["OCTAVE", "COARSE", "FINE", "TEXTURE SCALE", "CHARACTER"],
      "inspiration": "Granular synthesis of surface texture and Pierre Schaeffer's musique concrète approach to found sound sources",
      "bodyPart": "skin texture",
      "generated": "2026-02-23",
      "rating": null
    }
  ]
}
